{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Computing: Object Tracking and Motion Analysis\n",
    " In this coursework, you will implement various object tracking algorithms and motion analysis techniques using computer vision. The goal is to understand and apply different tracking approaches, analyse their performance, and evaluate their effectiveness under real-world conditions. This coursework is worth 7% of the total marks for the unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Detection Using GMM [10%]\n",
    "#### Objective:\n",
    "Implement Change Detection using a Gaussian Mixture Model (GMM) for object tracking from scratch. Follow the algorithm outlined in the provided lecture slide for modelling pixel changes.\n",
    "cv2.createBackgroundSubtractorMOG2, is not allowed.\n",
    "#### Implementation Details:\n",
    "Model the image as a mixture of Gaussians and classify each pixel as foreground or background. This will be done based on pixel probability distributions, as explained in the lecture. Update the Gaussian distributions per pixel to decide whether a pixel belongs to the background or foreground. Evaluate the effectiveness of the model in classifying moving objects. You can use cv2.VideoCapture(), cv2.cvtColor(),cv2.COLOR_BGR2GRAY(), cv2.waitKey().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Mixture Model (GMM) for Change Detection\n",
    "# -------------------------------------------------\n",
    "# Instructions: Below, I provide a code structure as a guidance to get you started. Of course you can use your own code structure to achieve the objective. Your marks will NOT be deducted if you use your own code structure :) \n",
    "# Complete the sections marked with '### ENTER YOUR CODE HERE ###' to implement \n",
    "# the Gaussian Mixture Model for background subtraction and change detection.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the GMMBackgroundSubtractor Class\n",
    "class GMMBackgroundSubtractor:\n",
    "    def __init__(self, frame_shape, num_gaussians= \"\"\"ENTER NUMBER OF GAUSSIANS\"\"\", learning_rate=\"\"\"ENTER LEARNING RATE\"\"\", threshold=\"\"\"ENTER THRESHOLD\"\"\"):\n",
    "        \"\"\"\n",
    "        Initialize Gaussian parameters: means, variances, and weights.\n",
    "\n",
    "        Args:\n",
    "            frame_shape (tuple): Shape of the input frame (height, width).\n",
    "            num_gaussians (int): Number of Gaussian models per pixel.\n",
    "            learning_rate (float): Rate at which the model updates.\n",
    "            threshold (float): Threshold for matching a pixel to a Gaussian.\n",
    "        \"\"\"\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Initialize the means, variances, and weights for each Gaussian\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "       \n",
    "        \n",
    "\n",
    "    def apply(self, frame):\n",
    "        \"\"\"\n",
    "        Apply GMM to detect foreground objects.\n",
    "\n",
    "        Args:\n",
    "            frame (ndarray): Input video frame.\n",
    "\n",
    "        Returns:\n",
    "            foreground_mask (ndarray): Binary mask indicating foreground pixels.\n",
    "        \"\"\"\n",
    "        # Convert frame to grayscale if it isn't already\n",
    "        if len(frame.shape) == 3:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        frame = frame.astype(np.float32)\n",
    "        \n",
    "        # Calculate the absolute difference between the frame and Gaussian means\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "\n",
    "        # Check which pixels match any of the Gaussians\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Step 1: Update matched Gaussians (means, variances, weights)\n",
    "        \n",
    "        # Normalize weights so they sum to 1\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Step 2: Classify Foreground\n",
    "      \n",
    "        \n",
    "        return foreground_mask.astype(np.uint8) * 255\n",
    "\n",
    "# ------------------- Main Code to Run the GMM ------------------- #\n",
    "\n",
    "# Load Video\n",
    "video_path = 'input_video.mp4'  # Replace with your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "# Read the first frame to get the frame shape\n",
    "\n",
    "\n",
    "# Initialize GMM Subtractor\n",
    "gmm_subtractor = GMMBackgroundSubtractor(frame.shape[:2])\n",
    "\n",
    "# Process the video frame by frame\n",
    "### ENTER YOUR CODE TO PROCESS THE VIDEO HERE ###\n",
    "\n",
    "# Release resources and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Lucas-Kanade (with OpenCV GMM) [10%]\n",
    "#### Objective\n",
    "In this task, students will be using Lucas-Kanade Optical Flow to track detected moving objects. You can use the OpenCV GMM cv2.createBackgroundSubtractorMOG2() for this section.  \n",
    "#### Implementation Details:\n",
    "Detect foreground objects using the OpenCV GMM, then extract feature points inside the foreground mask. Thereafter, implement and apply your custom Lucas-Kanade Optical Flow to track moving objects frame-by-frame. Visualise this via Motion vectors which are optical flow arrows showing direction and magnitude of object movement. You can use cv2.Sobel(), cv2.VideoCapture(), cv2.goodFeaturesToTrack(), cv2.cvtColor(),cv2.COLOR_BGR2GRAY(), cv2.waitKey(), and for visualization cv2.circle(),cv2.arrowedLine. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class LucasKanadeTracker:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect_features(self, frame, mask):\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        pass\n",
    "\n",
    "    def calculate_optical_flow(self, prev_frame, curr_frame, prev_points):\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        pass\n",
    "\n",
    "    def draw_motion_vectors(self, frame, prev_points, new_points, status):\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        pass\n",
    "\n",
    "# Load Video\n",
    "cap = cv2.VideoCapture('input_video.mp4')  # Replace with your video file\n",
    "\n",
    "### ENTER YOUR CODE TO PROCESS THE VIDEO HERE ###\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Matching for Object Tracking [10%] \n",
    "#### Objective:\n",
    "Students will implement template matching using a weighted histogram matching technique from scratch to track a target object across multiple frames in a video. Experiment with NCC to obtain the results.\n",
    "#### Implementation Details:\n",
    "User manually selects a target object in the first frame. Apply template matching to locate the object in subsequent frames. Experiment with the similarity metric:  NCC (Normalized Cross-Correlation) between template & search region. Draw a bounding box around the detected object in each frame (The best match is marked with a rectangle in each frame). You can use cv2.matchTemplate(),cv2.selectROI(),cv2.minMaxLoc (),cv2.TM_CCORR_NORMED (),cv2.COLOR_BGR2GRAY (), cv2.VideoCapture(), cv2.cvtColor(), cv2.waitKey(),cv2.normalize().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class TemplateMatcher:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_template(self, frame):\n",
    "        \"\"\"\n",
    "        Allow the user to manually select the target object in the first frame.\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Use cv2.selectROI() to select the region of interest (ROI).\n",
    "        pass\n",
    "\n",
    "    def match_template(self, frame, template):\n",
    "        \"\"\"\n",
    "        Apply template matching using Normalized Cross-Correlation (NCC).\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "     \n",
    "        pass\n",
    "\n",
    "    def draw_bounding_box(self, frame, top_left, template_size):\n",
    "        \"\"\"\n",
    "        Draw a bounding box around the detected object.\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Use cv2.rectangle() to draw the box.\n",
    "        pass\n",
    "\n",
    "# Load Video\n",
    "cap = cv2.VideoCapture('input_video.mp4')  # Replace with your video file\n",
    "\n",
    "### ENTER YOUR CODE TO PROCESS THE VIDEO HERE ###\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Template Matching for Object Tracking [5% + 10%]\n",
    "#### Objective:\n",
    "After implementing template matching, students should explore potential improvements.  The key challenges with template matching are: 1. Scale changes 2. Rotation Changes 3. Brightness/ contrast changes and Occlusions.\n",
    "#### Implementation Details:\n",
    "[A] Multi-Scale Template Matching (Handling Scale Changes)\n",
    "Instead of using a fixed-size template, track multiple scales: Resize the template to 3 different scales (of your choice) before matching. Match at different pyramid levels using cv2.pyrDown() and cv2.pyrUp(). You can use prebuilt functions: cv2.matchTemplate(),cv2.minMaxLoc(),cv2.resize().\n",
    "\n",
    "[B] Rotation-Invariant Matching\n",
    "Rotate the template at 3 different angles (of your choice)  and match each rotated version. You can use cv2.getRotationMatrix2D(),cv2.warpAffine().\n",
    "\n",
    "[C] Using Feature-Based Matching Instead of Pixel-Based Matching\n",
    "Template matching relies on raw pixel values, making it sensitive to changes. Instead of comparing pixel intensities, extract SIFT features and follow the algorithm for tracking by feature detection discussed in the lecture. You can use cv2.SIFT_create(), sift.detectAndCompute,cv2.BFMatcher(), cv2.drawMatches() function here to compare. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ImprovedTemplateMatcher:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def multi_scale_matching(self, frame, template):\n",
    "        \"\"\"\n",
    "        Perform multi-scale template matching to handle scale changes.\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Resize the template to different scales \n",
    "        pass\n",
    "\n",
    "    def rotation_invariant_matching(self, frame, template):\n",
    "        \"\"\"\n",
    "        Perform rotation-invariant template matching.\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Rotate the template at different angles \n",
    "        pass\n",
    "\n",
    "    def feature_based_matching(self, frame, template):\n",
    "        \"\"\"\n",
    "        Use SIFT feature detection for robust template matching.\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Use cv2.SIFT_create(), detectAndCompute() to extract features.\n",
    "        # Match features using cv2.BFMatcher() and visualize with cv2.drawMatches().\n",
    "        pass\n",
    "\n",
    "    def draw_bounding_box(self, frame, top_left, template_size):\n",
    "        \"\"\"\n",
    "        Draw bounding box around the detected object.\n",
    "        \"\"\"\n",
    "        ### ENTER YOUR CODE HERE ###\n",
    "        # Use cv2.rectangle() to draw the bounding box.\n",
    "        pass\n",
    "\n",
    "# Load Video\n",
    "cap = cv2.VideoCapture('input_video.mp4')  # Replace with your video file\n",
    "\n",
    "### ENTER YOUR CODE TO PROCESS THE VIDEO HERE ###\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
